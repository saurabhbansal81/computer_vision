{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2135e7",
   "metadata": {},
   "source": [
    "### Model Inferencing with Pretrained Faster RCNN with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d7bc86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2,FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a818e18",
   "metadata": {},
   "source": [
    "##### Download Pretrained Model & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f9034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # load model weights\n",
    "    weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    # load model\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=weights, box_score_thresh=0.7)\n",
    "    # set to evaluation mode\n",
    "    model.eval()\n",
    "    return model, weights.meta[\"categories\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026baa56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb8b64d9",
   "metadata": {},
   "source": [
    "##### Preprocessing Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c63bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # convert to tensor\n",
    "    image_tensor = F.to_tensor(image)\n",
    "\n",
    "    return image, image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa33b3a",
   "metadata": {},
   "source": [
    "##### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb41392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_prediction(model, image_tensor):\n",
    "    # add batch dimension\n",
    "    with torch.no_grad():\n",
    "        predictions = model([image_tensor])\n",
    "    \n",
    "    print(\"Model output\")\n",
    "    print(predictions)\n",
    "\n",
    "    return predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387cded1",
   "metadata": {},
   "source": [
    "##### Adding Bounding Box to our results for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff38f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(image, predictions, category_names):\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    image_np = cv2.ctvColor(image_np, cv2.Color_RGB2BGR)\n",
    "    boxes = predictions['boxes'].cpu().numpy().astype(int)\n",
    "    labels = predictions['labels'].cpu().numpy()\n",
    "    scores = predictions['scores'].cpu().numpy()\n",
    "\n",
    "    image_with_boxes = image_np.copy()\n",
    "\n",
    "    color_map = {}\n",
    "\n",
    "    for box, score, label in zip(boxes, scores, labels):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
